# Model Configuration for HandFlowMatchingDiT (Flow Matching + Graph-aware DiT)
# This config defines all static hyperparameters for the flow-matching hand DiT model.
# Graph constants (graph_consts) are expected to be provided at runtime by the DataModule
# via HandEncoderDataModule.get_graph_constants().

_target_: src.models.flow_matching_hand_dit.HandFlowMatchingDiT
_partial_: true  # allow trainer to inject graph_consts and (optionally) backbone_cfg at runtime

# -----------------------------------------------------------------------------
# 1. Core architecture hyperparameters
# -----------------------------------------------------------------------------
# d_model: token/channel dimension used throughout the hand encoder, scene backbone output,
#          and DiT blocks. Must match the backbone's out_dim.
d_model: 512

# DiT depth: number of stacked HandSceneGraphDiT blocks
#   - 4: 轻量级，适合快速实验
#   - 6: 默认推荐，表达能力与计算量平衡
#   - 8+: 更强但更耗时
dit_depth: 6

# Number of attention heads in each DiT block
#   - 要求 d_model 能被 dit_heads 整除
dit_heads: 8

# -----------------------------------------------------------------------------
# 2. Hand encoder configuration
# -----------------------------------------------------------------------------
# hand_encoder_type: 选择手部编码器结构
#   - "transformer": HandPointTokenEncoderTransformerBias（推荐）
#   - "egnn":        HandPointTokenEncoderEGNNLite
hand_encoder_type: transformer

# Number of graph encoder layers in the hand encoder
hand_encoder_layers: 3

# Number of Fourier feature frequencies used to encode relative positions
num_frequencies: 10

# -----------------------------------------------------------------------------
# 3. Scene backbone (object point cloud encoder)
# -----------------------------------------------------------------------------
# backbone_cfg: 点云编码 backbone 的配置，通常来自 `backbone` 配置组。
# 典型用法示例（在命令行或实验配置中）：
#   backbone: ptv3_sparse_perceiver
# 然后 trainer 侧可以执行：
#   model = instantiate(cfg.model, graph_consts=dm.get_graph_constants(), backbone_cfg=cfg.backbone)
backbone_cfg: ${backbone}

# -----------------------------------------------------------------------------
# 4. Flow Matching loss & regularization
# -----------------------------------------------------------------------------
# lambda_tangent: 切向约束损失权重
#   - 0.0: 只优化 flow matching loss，不做边长切向约束
#   - 1.0: 默认，兼顾生成质量与物理一致性
#   - 更高的值会更严格地约束边长，但可能略微影响多样性
lambda_tangent: 1.0

# -----------------------------------------------------------------------------
# 5. Optimization hyperparameters
# -----------------------------------------------------------------------------
# learning_rate: AdamW 学习率（HandFlowMatchingDiT.configure_optimizers 中使用）
learning_rate: 3e-4

# weight_decay: AdamW 权重衰减系数
weight_decay: 1e-2

# use_scheduler: 是否启用 CosineAnnealingLR 学习率调度器
use_scheduler: true

# scheduler_T_max: CosineAnnealingLR 的 T_max（以 epoch 为单位）
scheduler_T_max: 100

# -----------------------------------------------------------------------------
# 6. Sampling & constraint projection
# -----------------------------------------------------------------------------
# sample_num_steps: 采样时 ODE Euler 步数（从 t=0 积分到 t=1）
#   - 20: 快速粗略采样
#   - 40: 默认推荐
#   - 60+: 更细粒度积分，推理更慢
sample_num_steps: 40

# proj_num_iters: 每个采样时间步中 PBD 边长投影的迭代次数
#   - 0: 不做显式投影，只依赖网络和切向损失
#   - 1–3: 通常足够（默认 2）
proj_num_iters: 2

# proj_max_corr: 每次投影的最大相对修正幅度（防止数值不稳定）
proj_max_corr: 0.2

